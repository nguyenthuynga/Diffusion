{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score-Based Generative Modeling: Application for Sea Surface Turbidity Reconstruction\n",
    "This tutorial is a 3D input setting (2D dimension+1D for the time series) using Unet3D (with conv3D), Song's original tutorial for 2D setting can be found [here](https://colab.research.google.com/drive/120kYYBOVa1i0TD85RjlEkFjaWDxSFUx3?usp=sharing#scrollTo=21v75FhSkfCq) (but note that this Song's code is for MNIST dataset, 2D setting and unconditional generative setting). Song's paper: Yang Song, Jascha Sohl-Dickstein, Diederik P. Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole. \"[Score-Based Generative Modeling through Stochastic Differential Equations.](https://arxiv.org/pdf/2011.13456.pdf)\" Internation Conference on Learning Representations, 2021\n",
    "\n",
    "Before running this code, you can download the dataset (which is sea surface turbidity of the Dutch Wadden Sea, OSE from CMEMS) used in this tutorial [here](https://drive.google.com/drive/folders/1NpwSLr8HEOYcGbQWXY6gC__GcxO12Abt?usp=sharing) . We use satellite observation as gappy ground truth because we do not have access to gap-free ground truth. The input actually this gappy ground truth, which is further augmented with artificially added rectangular patches as you can see below figure. In that figure, you can see three different samples in the middle; these samples are generated using the mask (shown on the left as input), and we strive to make these samples closely resemble the gappy ground truth (shown on the right) by minimizing the loss function.\n",
    "\n",
    "\n",
    "![ncsnv2](https://github.com/nguyenthuynga/Diffusion/blob/main/Images/diffusion_generative.png?raw=true)\n",
    "\n",
    "\n",
    "Compared to Song's orginal tutorial, I made quite many changes. All the changes are marked by #change with a number, below are the main ones:\n",
    "- This is a conditional setting for tasks such as interpolation/mapping/reconstruction, where the score-based model UNet is designed to take two types of input: Gaussian noise and a mask as the condition (along with time step). The figure above demonstrates this: the mask (on the left) is used as the input to the score model. Our goal is to learn the distribution of the dataset effectively so that the model can generate outputs that closely resemble the ground truth (shown on the far right). The three images in the middle display samples generated by our conditional score model, illustrating how it generate different samples (from different Gaussian noise as input) under the mask as condition.\n",
    "- Customize the DataLoader to take our data as input (instead of MNIST). To avoid exploding gradient, we reduce the percentage of batches which has too less available data, apply gradient clipping within the PyTorch framework. Because we need a big dataset in as mentioned above, but my dataset is small (2K images) with the original size of 200*300, to increase the amount of data so train on a random small area of size 112*112, by doing that I can crop different areas as a way to augment the number of images.\n",
    "- Customize the loss function to process only non-NaN areas. \n",
    "- Training requires long time + big dataset. Since in this score-based model training setting, each epoch of training involves learning one step of denoising, while the whole denoising process encompasses around 500 steps. So, in each step, we learn a small thing. That is why: 1, we need many epochs learning. 2,  big dataset, because otherwise the training process is getting overfit before it actually learns something useful.\n",
    "- We customized for 3D setting in the Unet architecture, in both training and sampling phase.\n",
    "- Many other small changes that is noted in the code starting with “#change “...\n",
    "\n",
    "If something in the code isn't clear for you, don't hesitate to contact me at nga.nguyen@imt-atlantique.fr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ncsnv2](https://github.com/nguyenthuynga/Diffusion/blob/main/Images/random_crop_small_area.png?raw=true)\n",
    "\n",
    "Diffusion models require very large datasets; however, our dataset is relatively small. To mitigate overfitting, we implement augmentation by cropping and training only on smaller areas. This technique allows us to generate multiple random smaller images from each original image, effectively enriching our dataset by 5-10 times. The original images are 200x300 pixels, while the cropped areas are 112x112 pixels, as you can see we define below size_0 and size_1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing the GPU\n",
    "import os\n",
    "gpu = \"0\"  # The GPU number to use.\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu  # Ensure this line is in every cell that requires GPU usage.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the size of the (cropped) input image for 3D settings 1*time_window*size_0*size_1 (1 here standing for the channel, which is defaut one)\n",
    "size_0 = 112  # Spatial dimension for latitude\n",
    "size_1 = 112  # Spatial dimension for longtitude\n",
    "time_window = 16  # Temporal dimension, added to accommodate the 3D input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the datasets\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu\n",
    "import xarray as xr \n",
    "import numpy as np\n",
    "\n",
    "# Paths to the datasets\n",
    "path_GT=\"/Odyssey/private/n23nguye/data_nga/Delft3Dmodel_CMEMS_size200T300/CMEMS/GT_CMEMS_size200T300_log10.nc\" #path to the gappy ground truth, since we do not have gap free ground truth, we use gappy satellite observation as ground truth. \n",
    "# path_land=\"/DATASET/data_nga/Delft3Dmodel_CMEMS_size200T300/CMEMS/land_mask_CMEMS_size200T300.nc\" #path to the land mask, this is optional\n",
    "path_GT_with_artificialgappy=\"/Odyssey/private/n23nguye/data_nga/Delft3Dmodel_CMEMS_size200T300/CMEMS/Obs_patch_CMEMS_size200T300_log10_0.5RemovedCloud_correctVersion.nc\"#path to the gappy input, where we add some artificial square to remove the data. \n",
    "\n",
    "# Optionally, restrict the data loaded to a small time slice for initial checks\n",
    "time_slice = None  # e.g., slice(0, 20) to load only the first 20 time steps\n",
    "\n",
    "if time_slice is not None:\n",
    "    GT=xr.open_dataset(path_GT).isel(time=time_slice)\n",
    "    GT_with_artificialgappy=xr.open_dataset(path_GT_with_artificialgappy).isel(time=time_slice)\n",
    "else:\n",
    "    GT=xr.open_dataset(path_GT)\n",
    "    GT_with_artificialgappy=xr.open_dataset(path_GT_with_artificialgappy)\n",
    "\n",
    "# Display basic information about the loaded ground truth\n",
    "print(\"GT: \", GT)\n",
    "\n",
    "# Explore the subset of data: by defining slices for spatial cropping based on desired size\n",
    "lat_slice=slice(0, 0+size_0)\n",
    "lon_slice=slice(60, 60+size_1)\n",
    "GT_subset = GT.isel(lat=lat_slice, lon=lon_slice)\n",
    "GT_with_artificialgappy_subset = GT_with_artificialgappy.isel(lat=lat_slice, lon=lon_slice)\n",
    "\n",
    "# Print the subset dataset information\n",
    "print(\"GT_subset: \",GT_subset)\n",
    "print(\"GT_with_artificialgappy_subset: \",GT_with_artificialgappy_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate train and validation set, the year 2020 is used for validation, the remainning is used for training set\n",
    "GT_train = GT.sel(time=slice('2015-01-01', '2019-12-31'))\n",
    "GT_val = GT.sel(time='2020')\n",
    "\n",
    "print('GT_val', GT_val)\n",
    "\n",
    "GT_with_artificialgappy_train = GT_with_artificialgappy.sel(time=slice('2015-01-01', '2019-12-31'))\n",
    "GT_with_artificialgappy_val = GT_with_artificialgappy.sel(time='2020')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot GT and GT_subset to visualize the data for one specific day: note that in training process, the input is of size 112*112 as GT_subset, and not 200*300 as GT\n",
    "import matplotlib.pyplot as plt\n",
    "# Select the data for a specific time index\n",
    "time = 180\n",
    "\n",
    "# Load data for the specified time\n",
    "GT_time1 = GT.isel(time=time)\n",
    "GT_subset_time1 = GT_subset.isel(time=time)\n",
    "GT_with_artificialgappy_time1 = GT_with_artificialgappy.isel(time=time)\n",
    "GT_with_artificialgappy_subset_time1 = GT_with_artificialgappy_subset.isel(time=time)\n",
    "\n",
    "print(\"GT_subset_time1: \", GT_subset_time1)\n",
    "print(\"GT_with_artificialgappy_subset_time1: \", GT_with_artificialgappy_subset_time1)\n",
    "\n",
    "# Create a figure with 3 subplots\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(27, 6))\n",
    "\n",
    "# Plot the original data at specified time\n",
    "GT_time1.SPM.plot(ax=axes[0])\n",
    "axes[0].set_title(f'Original GT at Time {time}')\n",
    "\n",
    "# Plot the subset of the original data at specified time\n",
    "GT_subset_time1.SPM.plot(ax=axes[1])\n",
    "axes[1].set_title(f'Subset GT at Time {time}')\n",
    "\n",
    "# Plot the subset of artificially gappy data at specified time\n",
    "GT_with_artificialgappy_subset_time1.SPM.plot(ax=axes[2])\n",
    "axes[2].set_title(f'Artificially Gappy GT Subset at Time {time}')\n",
    "\n",
    "# Adjust layout and display the plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, the dataloader below will process 3D input (instead of 2D input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Technical remark: In below dataloader, you can see I used \"if valid_loss_mask.sum() <threshold:\" in  #change 54c: to avoid NaN loss due to large amount of NaN,\n",
    "because otherwise the gradient is exploding more frequent (if too much NaN values present in the input). We can remove this if condition as well, \n",
    "since anyway in the training process later on, I also exclude the batches wiht exploding gradient from the accumulating the final loss\"\"\"\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class XArrayDatasetWithMask(Dataset):\n",
    "    def __init__(self, GT, GT_mask, crop_size, output_size, time_window=None, transform=None):\n",
    "        \"\"\"\n",
    "        Dataset to handle ground truth and mask data.\n",
    "        Args:\n",
    "        GT (xarray.Dataset): Dataset containing the ground truth.\n",
    "        GT_mask (xarray.Dataset): Dataset containing the masks.\n",
    "        crop_size (tuple): Tuos.environ[\"CUDA_VISIBLE_DEVICES\"] = gpuple indicating the size of the crops.\n",
    "        transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.GT_data = GT['SPM'].values  # Assuming 'SPM' is the variable in the dataset\n",
    "        self.mask_data = GT_mask['SPM'].values  # Assuming mask data is stored similarly\n",
    "        self.crop_size = crop_size\n",
    "        self.output_size = output_size\n",
    "        self.transform = transform\n",
    "        self.time_window = time_window\n",
    "        self.random_crop = transforms.RandomCrop(crop_size)  # Random crop transformation\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.GT_data.shape[0] - self.time_window + 1  \n",
    "    \n",
    "    def __getitem__(self, idx): \n",
    "        gt_sample = self.GT_data[idx:idx+self.time_window]  \n",
    "        mask_sample = self.mask_data[idx:idx+self.time_window]\n",
    "        \n",
    "        gt_sample = torch.tensor(gt_sample, dtype=torch.float32).unsqueeze(1)#the size will be (time_window, 1, size_0, size_1 here)\n",
    "        mask_sample = torch.tensor(mask_sample, dtype=torch.float32).unsqueeze(1)\n",
    "        \n",
    "        # Apply the same random crop to all time steps\n",
    "        i, j, h, w = self.random_crop.get_params(gt_sample[0], self.random_crop.size)  # Use the first time step to get crop params\n",
    "        # print(\"gt_sample.shape before crop: \", gt_sample.shape)\n",
    "        gt_sample=transforms.functional.crop(gt_sample, i, j, h, w).squeeze(1).unsqueeze(0) # so that the dimension will be (time_window,1, size_0,size_1)\n",
    "        mask_sample=transforms.functional.crop(mask_sample, i, j, h, w).squeeze(1).unsqueeze(0) # so that the dimension will be (time_window,1, size_0,size_1)\n",
    "        # print(\"gt_sample.shape after crop: \",transforms.functional.crop(gt_sample, i, j, h, w).shape)\n",
    "        \n",
    "        ### return the sample only when there is valid values in mask_sample y\n",
    "        mask_x_not_nan = ~torch.isnan(gt_sample)  # True where x is not NaN\n",
    "        valid_loss_mask = mask_x_not_nan\n",
    "\n",
    "        threshold = np.prod(gt_sample.shape) * 0.1 #to avoid NaN loss due to large amount of NaN,  the quality and completeness of the input data directly impact the computation of loss.\n",
    "        if valid_loss_mask.sum() <threshold: # to avoid NaN loss due to large amount of NaN\n",
    "            # If all values are NaN, retry with a new random index\n",
    "            # This assumes the dataset is large enough to find a valid sample after a few tries\n",
    "            return self.__getitem__((idx + 1) % len(self))  # Ensure index stays within bounds\n",
    "        else:\n",
    "            # Return the pair of image and mask if the mask has non-NaN values\n",
    "            return gt_sample, mask_sample\n",
    "\n",
    "\n",
    "crop_size = (size_0, size_1)  # Define your crop size\n",
    "output_size=(size_0, size_1)#change 20: I change output size here\n",
    "\n",
    "\n",
    "#change 48b: separate train and val here\n",
    "#change 49e: add time window here\n",
    "train_dataset = XArrayDatasetWithMask(GT_train, GT_with_artificialgappy_train, crop_size=crop_size, output_size=output_size, time_window=time_window)\n",
    "val_dataset = XArrayDatasetWithMask(GT_val, GT_with_artificialgappy_val, crop_size=crop_size, output_size=output_size, time_window=time_window)\n",
    "\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "# Testing the shape in DataLoader\n",
    "for gt_sample, mask_sample in train_data_loader:\n",
    "    print(\"Shape GT :\", gt_sample.shape)\n",
    "    print(\"Shape mask :\", mask_sample.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) Exploring some features of the dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for gt_sample, mask_sample in train_data_loader:\n",
    "    print(\"Shape GT:\", gt_sample.shape)\n",
    "    print(\"Shape mask:\", mask_sample.shape)\n",
    "\n",
    "    sample_number=10\n",
    "    # Plot the first sample in the batch\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    ax[0].imshow(gt_sample[sample_number][0,0], cmap='gray')#change 49f and change 50: plot only the 1st time window of the input\n",
    "    ax[0].set_title('Ground Truth time 0')\n",
    "    ax[0].axis('off')  # Hide the axes ticks\n",
    "    # Show the mask sample\n",
    "    ax[1].imshow(mask_sample[sample_number][0,0], cmap='gray')\n",
    "    ax[1].set_title('Mask time 0')\n",
    "    ax[1].axis('off')  # Hide the axes ticks\n",
    "    plt.show()\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    ax[0].imshow(gt_sample[sample_number][0,1], cmap='gray')#change 49f and change 50: plot only the 1st time window of the input\n",
    "    ax[0].set_title('Ground Truth time 1')\n",
    "    ax[0].axis('off')  # Hide the axes ticks\n",
    "    # Show the mask sample\n",
    "    ax[1].imshow(mask_sample[sample_number][0,1], cmap='gray')\n",
    "    ax[1].set_title('Mask time 1')\n",
    "    ax[1].axis('off')  # Hide the axes ticks\n",
    "    plt.show()\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    ax[0].imshow(gt_sample[sample_number][0,2], cmap='gray')#change 49f and change 50: plot only the 1st time window of the input\n",
    "    ax[0].set_title('Ground Truth time 2')\n",
    "    ax[0].axis('off')  # Hide the axes ticks\n",
    "    # Show the mask sample\n",
    "    ax[1].imshow(mask_sample[sample_number][0,2], cmap='gray')\n",
    "    ax[1].set_title('Mask time 2')\n",
    "    ax[1].axis('off')  # Hide the axes ticks\n",
    "    plt.show()\n",
    "\n",
    "    break  # Only process the first batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction about the score-based model approach\n",
    "\n",
    "### Score and Score-Based Models\n",
    "Given a probablity density function $p(\\mathbf{x})$, we define the *score* as $$\\nabla_\\mathbf{x} \\log p(\\mathbf{x}).$$ As you might guess, score-based generative models are trained to estimate $\\nabla_\\mathbf{x} \\log p(\\mathbf{x})$. Unlike likelihood-based models such as flow models or autoregressive models, score-based models do not have to be normalized and are easier to parameterize. For example, consider a non-normalized statistical model $p_\\theta(\\mathbf{x}) = \\frac{e^{-E_\\theta(\\mathbf{x})}}{Z_\\theta}$, where $E_\\theta(\\mathbf{x}) \\in \\mathbb{R}$ is called the energy function and $Z_\\theta$ is an unknown normalizing constant that makes $p_\\theta(\\mathbf{x})$ a proper probability density function. The energy function is typically parameterized by a flexible neural network. When training it as a likelihood model, we need to know the normalizing constant $Z_\\theta$ by computing complex high-dimensional integrals, which is typically intractable. In constrast, when computing its score, we obtain $\\nabla_\\mathbf{x} \\log p_\\theta(\\mathbf{x}) = -\\nabla_\\mathbf{x} E_\\theta(\\mathbf{x})$ which does not require computing the normalizing constant $Z_\\theta$.\n",
    "\n",
    "In fact, any neural network that maps an input vector $\\mathbf{x} \\in \\mathbb{R}^d$ to an output vector $\\mathbf{y} \\in \\mathbb{R}^d$ can be used as a score-based model, as long as the output and input have the same dimensionality. This yields huge flexibility in choosing model architectures.\n",
    "\n",
    "### Perturbing Data with a Diffusion Process\n",
    "\n",
    "In order to generate samples with score-based models, we need to consider a [diffusion process](https://en.wikipedia.org/wiki/Diffusion_process) that corrupts data slowly into random noise. Scores will arise when we reverse this diffusion process for sample generation. You will see this later in the notebook.\n",
    "\n",
    "A diffusion process is a [stochastic process](https://en.wikipedia.org/wiki/Stochastic_process#:~:text=A%20stochastic%20or%20random%20process%20can%20be%20defined%20as%20a,an%20element%20in%20the%20set.) similar to [Brownian motion](https://en.wikipedia.org/wiki/Brownian_motion). Their paths are like the trajectory of a particle submerged in a flowing fluid, which moves randomly due to unpredictable collisions with other particles. Let $\\{\\mathbf{x}(t) \\in \\mathbb{R}^d \\}_{t=0}^T$ be a diffusion process, indexed by the continuous time variable $t\\in [0,T]$. A diffusion process is governed by a stochastic differential equation (SDE), in the following form\n",
    "\n",
    "\\begin{align*}\n",
    "d \\mathbf{x} = \\mathbf{f}(\\mathbf{x}, t) d t + g(t) d \\mathbf{w},\n",
    "\\end{align*}\n",
    "\n",
    "where $\\mathbf{f}(\\cdot, t): \\mathbb{R}^d \\to \\mathbb{R}^d$ is called the *drift coefficient* of the SDE, $g(t) \\in \\mathbb{R}$ is called the *diffusion coefficient*, and $\\mathbf{w}$ represents the standard Brownian motion. You can understand an SDE as a stochastic generalization to ordinary differential equations (ODEs). Particles moving according to an SDE not only follows the deterministic drift $\\mathbf{f}(\\mathbf{x}, t)$, but are also affected by the random noise coming from $g(t) d\\mathbf{w}$. From now on, we use $p_t(\\mathbf{x})$ to denote the distribution of $\\mathbf{x}(t)$. \n",
    "\n",
    "For score-based generative modeling, we will choose a diffusion process such that $\\mathbf{x}(0) \\sim p_0$, and $\\mathbf{x}(T) \\sim p_T$. Here $p_0$ is the data distribution where we have a dataset of i.i.d. samples, and $p_T$ is the prior distribution that has a tractable form and easy to sample from. The noise perturbation by the diffusion process is large enough to ensure $p_T$ does not depend on $p_0$.\n",
    "\n",
    "### Reversing the Diffusion Process Yields Score-Based Generative Models\n",
    "By starting from a sample from the prior distribution $p_T$ and reversing the diffusion process, we will be able to obtain a sample from the data distribution $p_0$. Crucially, the reverse process is a diffusion process running backwards in time. It is given by the following reverse-time SDE\n",
    "\n",
    "\\begin{align}\n",
    "  d\\mathbf{x} = [\\mathbf{f}(\\mathbf{x}, t) - g^2(t)\\nabla_{\\mathbf{x}}\\log p_t(\\mathbf{x})] dt + g(t) d\\bar{\\mathbf{w}},\n",
    "\\end{align}\n",
    "\n",
    "where $\\bar{\\mathbf{w}}$ is a Brownian motion in the reverse time direction, and $dt$ represents an infinitesimal negative time step. This reverse SDE can be computed once we know the drift and diffusion coefficients of the forward SDE, as well as the score of $p_t(\\mathbf{x})$ for each $t\\in[0, T]$.\n",
    "\n",
    "The overall intuition of score-based generative modeling with SDEs can be summarized in the illustration below\n",
    "\n",
    "![ncsnv2](https://github.com/nguyenthuynga/Diffusion/blob/main/Images/diffusion_scorebased.png?raw=true)\n",
    "\n",
    "\n",
    "### Score Estimation\n",
    "\n",
    "Based on the above intuition, we can use the time-dependent score function $\\nabla_\\mathbf{x} \\log p_t(\\mathbf{x})$ to construct the reverse-time SDE, and then solve it numerically to obtain samples from $p_0$ using samples from a prior distribution $p_T$. We can train a time-dependent score-based model $s_\\theta(\\mathbf{x}, t)$ to approximate $\\nabla_\\mathbf{x} \\log p_t(\\mathbf{x})$, using the following weighted sum of [denoising score matching](http://www.iro.umontreal.ca/~vincentp/Publications/smdae_techreport.pdf) objectives.\n",
    "\n",
    "\\begin{align}\n",
    "\\min_\\theta \\mathbb{E}_{t\\sim \\mathcal{U}(0, T)} [\\lambda(t) \\mathbb{E}_{\\mathbf{x}(0) \\sim p_0(\\mathbf{x})}\\mathbf{E}_{\\mathbf{x}(t) \\sim p_{0t}(\\mathbf{x}(t) \\mid \\mathbf{x}(0))}[ \\|s_\\theta(\\mathbf{x}(t), t) - \\nabla_{\\mathbf{x}(t)}\\log p_{0t}(\\mathbf{x}(t) \\mid \\mathbf{x}(0))\\|_2^2]],\n",
    "\\end{align}\n",
    "where $\\mathcal{U}(0,T)$ is a uniform distribution over $[0, T]$, $p_{0t}(\\mathbf{x}(t) \\mid \\mathbf{x}(0))$ denotes the transition probability from $\\mathbf{x}(0)$ to $\\mathbf{x}(t)$, and $\\lambda(t) \\in \\mathbb{R}_{>0}$ denotes a positive weighting function.\n",
    "\n",
    "In the objective, the expectation over $\\mathbf{x}(0)$ can be estimated with empirical means over data samples from $p_0$. The expectation over $\\mathbf{x}(t)$ can be estimated by sampling from $p_{0t}(\\mathbf{x}(t) \\mid \\mathbf{x}(0))$, which is efficient when the drift coefficient $\\mathbf{f}(\\mathbf{x}, t)$ is affine. The weight function $\\lambda(t)$ is typically chosen to be inverse proportional to $\\mathbb{E}[\\|\\nabla_{\\mathbf{x}}\\log p_{0t}(\\mathbf{x}(t) \\mid \\mathbf{x}(0)) \\|_2^2]$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5JnbivYqLDLI"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-Dependent Score-Based Model\n",
    "\n",
    "There are no restrictions on the network architecture of time-dependent score-based models, except that their output should have the same dimensionality as the input, and they should be conditioned on time.\n",
    "\n",
    "Several useful tips on architecture choice:\n",
    "* It usually performs well to use the [U-net](https://arxiv.org/abs/1505.04597) architecture as the backbone of the score network $s_\\theta(\\mathbf{x}, t)$,\n",
    "\n",
    "* We can incorporate the time information via [Gaussian random features](https://arxiv.org/abs/2006.10739). Specifically, we first sample $\\omega \\sim \\mathcal{N}(\\mathbf{0}, s^2\\mathbf{I})$ which is subsequently fixed for the model (i.e., not learnable). For a time step $t$, the corresponding Gaussian random feature is defined as \n",
    "\\begin{align}\n",
    "  [\\sin(2\\pi \\omega t) ; \\cos(2\\pi \\omega t)],\n",
    "\\end{align}\n",
    "where $[\\vec{a} ; \\vec{b}]$ denotes the concatenation of vector $\\vec{a}$ and $\\vec{b}$. This Gaussian random feature can be used as an encoding for time step $t$ so that the score network can condition on $t$ by incorporating this encoding. We will see this further in the code.\n",
    "\n",
    "* We can rescale the output of the U-net by $1/\\sqrt{\\mathbb{E}[\\|\\nabla_{\\mathbf{x}}\\log p_{0t}(\\mathbf{x}(t) \\mid \\mathbf{x}(0)) \\|_2^2]}$. This is because the optimal $s_\\theta(\\mathbf{x}(t), t)$ has an $\\ell_2$-norm close to $\\mathbb{E}[\\|\\nabla_{\\mathbf{x}}\\log p_{0t}(\\mathbf{x}(t) \\mid \\mathbf{x}(0))]\\|_2$, and the rescaling helps capture the norm of the true score. Recall that the training objective contains sums of the form\n",
    "\\begin{align*}\n",
    "\\mathbf{E}_{\\mathbf{x}(t) \\sim p_{0t}(\\mathbf{x}(t) \\mid \\mathbf{x}(0))}[ \\|s_\\theta(\\mathbf{x}(t), t) - \\nabla_{\\mathbf{x}(t)}\\log p_{0t}(\\mathbf{x}(t) \\mid \\mathbf{x}(0))\\|_2^2].\n",
    "\\end{align*}\n",
    "Therefore, it is natural to expect that the optimal score model $s_\\theta(\\mathbf{x}, t) \\approx \\nabla_{\\mathbf{x}(t)} \\log p_{0t}(\\mathbf{x}(t) \\mid \\mathbf{x}(0))$.\n",
    "\n",
    "* Use [exponential moving average](https://discuss.pytorch.org/t/how-to-apply-exponential-moving-average-decay-for-variables/10856/3) (EMA) of weights when sampling. This can greatly improve sample quality, but requires slightly longer training time, and requires more work in implementation. We do not include this in this tutorial, but highly recommend it when you employ score-based generative modeling to tackle more challenging real problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a time-dependent score-based model\n",
    "#### Note that below it is 3D setting with UNet 3D, and conditional setting.\n",
    "x= torch.cat((x, y), 1) where x is our generated state and y is the condition (which is a mask/gappy input in this case study)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange\n",
    "\n",
    "def one_param(m):\n",
    "    \"get model first parameter\"\n",
    "    return next(iter(m.parameters()))\n",
    "\n",
    "\n",
    "class GaussianFourierProjection(nn.Module):\n",
    "    def __init__(self, embed_dim, scale=30.):\n",
    "        super().__init__()\n",
    "    # Randomly sample weights during initialization. These weights are fixed\n",
    "    # during optimization and are not trainable.\n",
    "        self.W = nn.Parameter(torch.randn(embed_dim // 2) * scale, requires_grad=False)\n",
    "    def forward(self, x):\n",
    "        x_proj = x[:, None] * self.W[None, :] * 2 * math.pi\n",
    "        return torch.cat([torch.sin(x_proj), torch.cos(x_proj)], dim=-1)\n",
    "\n",
    "\n",
    "class Dense(nn.Module):\n",
    "    \"\"\"A fully connected layer that reshapes outputs to feature maps.\n",
    "  Allow time repr to input additively from the side of a convolution layer.\n",
    "  \"\"\"\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(input_dim, output_dim)\n",
    "    def forward(self, x):\n",
    "        return self.dense(x)[..., None, None,None] #change 50f: add one dimension here with one more None\n",
    "\n",
    "\n",
    "#change:the dimension will be (time_window,1, size_0,size_1), and use conv3d/ConvTranspose3d instead of 2d setting\n",
    "class UNet_Tranformer_attrb1(nn.Module):\n",
    "    \"\"\"A time-dependent score-based model built upon U-Net architecture.\"\"\"\n",
    "\n",
    "    def __init__(self, marginal_prob_std, channels=[32, 64, 128, 256], embed_dim=256, #can increase the channel to make the Unet wider, originally it is [32, 64, 128, 256], but [64, 128, 256, 512] can be better\n",
    "                 text_dim=1, nAttr=40):\n",
    "        \"\"\"Initialize a time-dependent score-based network.\n",
    "\n",
    "        Args:\n",
    "          marginal_prob_std: A function that takes time t and gives the standard\n",
    "            deviation of the perturbation kernel p_{0t}(x(t) | x(0)).\n",
    "          channels: The number of channels for feature maps of each resolution.\n",
    "          embed_dim: The dimensionality of Gaussian random feature embeddings.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Gaussian random feature embedding layer for time\n",
    "        self.embed = nn.Sequential(GaussianFourierProjection(embed_dim=embed_dim),\n",
    "                                   nn.Linear(embed_dim, embed_dim))\n",
    "        # Encoding layers where the resolution decreases\n",
    "        self.conv1 = nn.Conv3d(2, channels[0], 3, stride=1,padding=1, bias=False)#2 here because we input both x and y\n",
    "        self.dense1 = Dense(embed_dim, channels[0])\n",
    "        self.gnorm1 = nn.GroupNorm(4, num_channels=channels[0])\n",
    "        self.conv2 = nn.Conv3d(channels[0], channels[1], 3, stride=2,padding=1, bias=False, )\n",
    "        self.dense2 = Dense(embed_dim, channels[1])\n",
    "        self.gnorm2 = nn.GroupNorm(32, num_channels=channels[1])\n",
    "        self.conv3 = nn.Conv3d(channels[1], channels[2], 3, stride=2,padding=1, bias=False, )\n",
    "        self.dense3 = Dense(embed_dim, channels[2])\n",
    "        self.gnorm3 = nn.GroupNorm(32, num_channels=channels[2])\n",
    "        # self.attn3 = SpatialTransformer(channels[2], text_dim)\n",
    "        self.conv4 = nn.Conv3d(channels[2], channels[3], 3, stride=2,padding=1, bias=False, )\n",
    "        self.dense4 = Dense(embed_dim, channels[3])\n",
    "        self.gnorm4 = nn.GroupNorm(32, num_channels=channels[3])\n",
    "        # self.attn4 = SpatialTransformer(channels[3], text_dim)\n",
    "\n",
    "        # Decoding layers where the resolution increases\n",
    "        self.tconv4 = nn.ConvTranspose3d(channels[3], channels[2], 3, stride=2, bias=False, padding=1, output_padding=1) #change 25b: add padding here\n",
    "        self.dense5 = Dense(embed_dim, channels[2])\n",
    "        self.tgnorm4 = nn.GroupNorm(32, num_channels=channels[2])\n",
    "        # self.attn5 = SpatialTransformer(channels[2], text_dim)\n",
    "        self.tconv3 = nn.ConvTranspose3d(channels[2], channels[1], 3, stride=2, bias=False,\n",
    "                                          padding=1, output_padding=1)  # , output_padding=1)     #  + channels[2]\n",
    "        self.dense6 = Dense(embed_dim, channels[1])\n",
    "        self.tgnorm3 = nn.GroupNorm(32, num_channels=channels[1])\n",
    "        self.tconv2 = nn.ConvTranspose3d(channels[1], channels[0], 3, stride=2, bias=False,\n",
    "                                        padding=1, output_padding=1)  # , output_padding=1)     #  + channels[1]\n",
    "        self.dense7 = Dense(embed_dim, channels[0])\n",
    "        self.tgnorm2 = nn.GroupNorm(32, num_channels=channels[0])\n",
    "        self.tconv1 = nn.ConvTranspose3d(channels[0], 1, 3, stride=1,padding=1)  # + channels[0] #change 49o: must be time window in the output here\n",
    "\n",
    "        # The swish activation function\n",
    "        self.act = nn.SiLU()  # lambda x: x * torch.sigmoid(x)\n",
    "        self.marginal_prob_std = marginal_prob_std\n",
    "        self.cond_embed = nn.Embedding(nAttr + 1, text_dim, padding_idx=nAttr)  # +1 for the padding index\n",
    "\n",
    "    def forward(self, x, t, y=None):\n",
    "        # Obtain the Gaussian random feature embedding for t\n",
    "        embed = self.act(self.embed(t))\n",
    "        # print('y', y.shape)\n",
    "        # print('x', x.shape)\n",
    "\n",
    "        x= torch.cat((x, y), 1)\n",
    "        # print('x after concating y', x.shape)\n",
    "\n",
    "        # print('conv1 before add dense', self.conv1(x).shape)\n",
    "        # print('dense1', self.dense1(embed).shape)\n",
    "        h1 = self.conv1(x) + self.dense1(embed)\n",
    "        # print('conv1 after add dense', h1.shape)\n",
    "\n",
    "        h1 = self.act(self.gnorm1(h1))\n",
    "\n",
    "        # print('conv2 before add dense', self.conv2(h1).shape)\n",
    "        # print('dense2', self.dense2(embed).shape)\n",
    "\n",
    "        h2 = self.conv2(h1) + self.dense2(embed)\n",
    "        # print('conv2', h2.shape)\n",
    "        h2 = self.act(self.gnorm2(h2))\n",
    "        h3 = self.conv3(h2) + self.dense3(embed)\n",
    "        # print('h3', h3.shape)\n",
    "        h3 = self.act(self.gnorm3(h3))\n",
    "\n",
    "        h4 = self.conv4(h3) + self.dense4(embed)\n",
    "        h4 = self.act(self.gnorm4(h4))\n",
    "        # print('h4', h4.shape)\n",
    "        \n",
    "        \n",
    "        # Decoding path\n",
    "        h = self.tconv4(h4) + self.dense5(embed)\n",
    "        # print('tconv4', h.shape)\n",
    "        ## Skip connection from the encoding path\n",
    "        h = self.act(self.tgnorm4(h))\n",
    "\n",
    "        h = self.tconv3(h + h3) + self.dense6(embed)\n",
    "        # print('tconv3', h.shape)\n",
    "        h = self.act(self.tgnorm3(h))\n",
    "        h = self.tconv2(h + h2) + self.dense7(embed)\n",
    "        # print('tconv2', h.shape)\n",
    "        h = self.act(self.tgnorm2(h))\n",
    "        h = self.tconv1(h + h1)\n",
    "        # print('tconv1', h.shape)\n",
    "\n",
    "        # Normalize output\n",
    "        h = h / self.marginal_prob_std(t)[:,None, None, None, None]#change 55: add one dimension for 3D setting here\n",
    "        # print('final output', h.shape)\n",
    "        # print(\"self.marginal_prob_std(t) 3D setting:\", self.marginal_prob_std(t))\n",
    "        return h\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with Weighted Sum of Denoising Score Matching Objectives\n",
    "\n",
    "Now let's get our hands dirty on training. First of all, we need to specify an SDE that perturbs the data distribution $p_0$ to a prior distribution $p_T$. We choose the following SDE\n",
    "\\begin{align*}\n",
    "d \\mathbf{x} = \\sigma^t d\\mathbf{w}, \\quad t\\in[0,1]\n",
    "\\end{align*}\n",
    "In this case,\n",
    "\\begin{align*}\n",
    "p_{0t}(\\mathbf{x}(t) \\mid \\mathbf{x}(0)) = \\mathcal{N}\\bigg(\\mathbf{x}(t); \\mathbf{x}(0), \\frac{1}{2\\log \\sigma}(\\sigma^{2t} - 1) \\mathbf{I}\\bigg).\n",
    "\\end{align*}\n",
    "We will see the proof below.\n",
    "\n",
    "(In this case, we can choose the weighting function $\\lambda(t) = \\frac{1}{2 \\log \\sigma}(\\sigma^{2t} - 1)$.)\n",
    "\n",
    "#### Solution to the SDE\n",
    "\n",
    "For an SDE of the form $ dx = \\sigma^t \\, dw $, the solution involves integrating the diffusion term over time:\n",
    "\n",
    "$$\n",
    "\\mathbf{x}(t) = \\mathbf{x}(0) + \\int_0^t \\sigma^s \\, d\\mathbf{w}_s\n",
    "$$\n",
    "\n",
    "#### Properties of the Integral\n",
    "\n",
    "- **Mean**: The integral of a deterministic function against Brownian motion is Gaussian with mean zero because Brownian motion has zero drift.\n",
    "  \n",
    "- **Variance**: The variance of the integral $ \\int_0^t \\sigma^s \\, d\\mathbf{w}_s $ is given by:\n",
    "  \n",
    "  $$\n",
    "  \\text{Var}\\left(\\int_0^t \\sigma^s \\, d\\mathbf{w}_s\\right) = \\int_0^t (\\sigma^s)^2 \\, ds  = \\frac{\\sigma^{2t} - 1}{2 \\log \\sigma}\n",
    "  $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the SDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Set up the SDE\n",
    "import functools  # Import the functools module\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu\n",
    "device = 'cuda' #@param ['cuda', 'cpu'] {'type':'string'}\n",
    "\n",
    "def marginal_prob_std(t, sigma):\n",
    "  \"\"\"Compute the mean and standard deviation of $p_{0t}(x(t) | x(0))$.\n",
    "\n",
    "  Args:\n",
    "    t: A vector of time steps.\n",
    "    sigma: The $\\sigma$ in our SDE.\n",
    "\n",
    "  Returns:\n",
    "    The standard deviation.\n",
    "  \"\"\"\n",
    "  t = torch.tensor(t, device=device)\n",
    "  return torch.sqrt((sigma**(2 * t) - 1.) / 2. / np.log(sigma))\n",
    "\n",
    "def diffusion_coeff(t, sigma):\n",
    "  \"\"\"Compute the diffusion coefficient of our SDE.\n",
    "\n",
    "  Args:\n",
    "    t: A vector of time steps.\n",
    "    sigma: The $\\sigma$ in our SDE.\n",
    "\n",
    "  Returns:\n",
    "    The vector of diffusion coefficients.\n",
    "  \"\"\"\n",
    "  return torch.tensor(sigma**t, device=device)\n",
    "\n",
    "sigma =  25.0#@param {'type':'number'}\n",
    "marginal_prob_std_fn = functools.partial(marginal_prob_std, sigma=sigma)\n",
    "diffusion_coeff_fn = functools.partial(diffusion_coeff, sigma=sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the loss function\n",
    " Note that this is the loss in 3D setting (one dimension extension), and the loss is applied only for Non Nan area\n",
    " To understand the loss, let's take a small 1D example here.\n",
    " We do **not** learn the gradient of the marginal distribution: $\n",
    "\\nabla_{x_t} \\log p_t(x_t)\n",
    "$\n",
    "\n",
    "Instead, we learn the gradient of the **conditional distribution**:\n",
    "\n",
    "$$\n",
    "\\nabla_{x_t} \\log p_t(x_t \\mid x_0)\n",
    "$$\n",
    "\n",
    "This is because $ p_t(x_t \\mid x_0) $ is a **known Gaussian**, resulting from the forward process:\n",
    "\n",
    "$$\n",
    "x_t = x_0 + \\sigma_t \\cdot \\epsilon, \\quad \\epsilon \\sim \\mathcal{N}(0, I)\n",
    "\\Rightarrow x_t \\mid x_0 \\sim \\mathcal{N}(x_0, \\sigma_t^2)\n",
    "$$\n",
    "\n",
    "Its score is analytically tractable:\n",
    "$$\n",
    "\\nabla_{x_t} \\log p_t(x_t \\mid x_0) = -\\frac{x_t - x_0}{\\sigma_t^2}\n",
    "$$\n",
    "\n",
    "\n",
    "**Intuition:** Learning the score function $\\nabla_{x_t} \\log p_t(x_t \\mid x_0)$ is equivalent to learning the added noise direction at each time step, i.e., learning how to denoise.\n",
    "\n",
    "Recall the forward process:\n",
    "$$\n",
    "x_t = x_0 + \\sigma_t \\cdot \\epsilon, \\quad \\epsilon \\sim \\mathcal{N}(0, 1)\n",
    "\\Rightarrow x_t \\mid x_0 \\sim \\mathcal{N}(x_0, \\sigma_t^2)\n",
    "$$\n",
    "\n",
    "**Example:\n",
    "$$\n",
    "x_0 = 1.2, \\quad \\sigma_t = 0.5, \\quad \\epsilon = -0.4\n",
    "\\Rightarrow x_t = 1.2 + 0.5 \\cdot (-0.4) = 1.0\n",
    "$$\n",
    "\n",
    "Compute the score:\n",
    "$$\n",
    "\\nabla_{x_t} \\log p_t(x_t \\mid x_0) = -\\frac{1.0 - 1.2}{0.5^2} = \\frac{0.2}{0.25} = 0.8\n",
    "$$\n",
    "**Conclusion:** The target score is fully known (after sampling the noise $\\epsilon$) and can be used to supervise the network prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Define the loss function (double click to expand or collapse)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu\n",
    "\n",
    "#change: customize the loss to adress NaN values \n",
    "def loss_fn(model, x,y, marginal_prob_std, eps=1e-5):#change: add y in the loss since we need it in the conditional model\n",
    "  \"\"\"The loss function for training score-based generative models.\n",
    "\n",
    "  Args:\n",
    "    model: A PyTorch model instance that represents a\n",
    "      time-dependent score-based model.\n",
    "    x: A mini-batch of training data.\n",
    "    marginal_prob_std: A function that gives the standard deviation of\n",
    "      the perturbation kernel.\n",
    "    eps: A tolerance value for numerical stability.\n",
    "  \"\"\"\n",
    "\n",
    "  mask = ~torch.isnan(x)  # mask is True where x is not NaN\n",
    "  x = torch.nan_to_num(x, nan=0.0)  # Replace NaNs with 0\n",
    "\n",
    "  y = torch.nan_to_num(y, nan=0.0)  #change: Replace NaNs with 0 for y as well\n",
    "  \n",
    "  random_t = torch.rand(x.shape[0], device=x.device) * (1. - eps) + eps\n",
    "  z = torch.randn_like(x)\n",
    "  std = marginal_prob_std(random_t)\n",
    "  perturbed_x = x + z * std[:, None, None, None, None] \n",
    "  score = model(perturbed_x, t=random_t, y=y)#change: add y in the model\n",
    "  \n",
    "  # Step 2: Compute the loss \n",
    "  loss = (score * std[:, None, None, None, None] + z) ** 2 \n",
    "  \n",
    "  # Step 3: Apply the mask\n",
    "  loss = loss * mask.float()  # Only consider non-NaN pixels\n",
    "  \n",
    "  # Step 4: Compute the mean loss over valid pixels\n",
    "  loss = torch.sum(loss, dim=(1, 2, 3))  # Sum over spatial dimensions\n",
    "  valid_pixel_count = torch.sum(mask, dim=(1, 2, 3))  # Count valid pixels\n",
    "  loss = loss / valid_pixel_count  # Normalize loss by valid pixel count\n",
    "  loss = torch.mean(loss)  # Average over the batch\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training process\n",
    "- Exploding gradient is detected and then excluded using condition if torch.isnan(loss): as below\n",
    "- torch.nn.utils.clip_grad_norm_(score_model.parameters(), max_norm=1.0) to avoid too big jump of the gradient even if it is not exploding\n",
    "- lr is set quite small, scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[200, 400,600,800], gamma=0.5)# reduce the learing rate in every 200 epochs with the factor of gamma\n",
    "\n",
    "(Optional) You might need to change the path of check point below, if no check point is detected, the model is training from beginning\n",
    "#### I put small n_epochs so that it run faster but you might need around 1000 epochs to get better performance (but also might be a bit overfitting!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Training (double click to expand or collapse)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu\n",
    "\n",
    "import torch\n",
    "import functools\n",
    "from torch.optim import Adam, lr_scheduler#change: add scheduler to reduce lr\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from tqdm import trange\n",
    "\n",
    "n_epochs =  300#@param {'type':'integer'}\n",
    "## size of a mini-batch\n",
    "batch_size =  16 #@param {'type':'integer'}\n",
    "\n",
    "lr= 0.0001#@param {'type':'number'} for example 1e-4\n",
    "\n",
    "\n",
    "##Check if the checkpoint exists, if yes it will continue train from the checkpoint path, otherwise it will training from beginning\n",
    "checkpoint_path = f'.pth'\n",
    "\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    # Load the pre-trained checkpoint from disk\n",
    "    ckpt = torch.load(checkpoint_path, map_location=device)\n",
    "    \n",
    "    # Inspect the checkpoint dictionary to see what keys it contains\n",
    "    print(\"Checkpoint keys:\", ckpt.keys())\n",
    "    \n",
    "    # Initialize the model\n",
    "    score_model = torch.nn.DataParallel(UNet_Tranformer_attrb1(marginal_prob_std=marginal_prob_std_fn))\n",
    "    score_model = score_model.to(device)\n",
    "    \n",
    "    # Load the model state dictionary\n",
    "    if 'model_state_dict' in ckpt:\n",
    "        score_model.load_state_dict(ckpt['model_state_dict'])\n",
    "    else:\n",
    "        # If the checkpoint doesn't have 'model_state_dict', assume it contains the model state directly\n",
    "        score_model.load_state_dict(ckpt)\n",
    "\n",
    "    # Create the optimizer and load its state\n",
    "    optimizer = Adam(score_model.parameters(), lr=lr)\n",
    "    if 'optimizer_state_dict' in ckpt:\n",
    "        optimizer.load_state_dict(ckpt['optimizer_state_dict'])\n",
    "\n",
    "    # Retrieve the last epoch\n",
    "    start_epoch = 0#ckpt.get('epoch', -1) + 1\n",
    "\n",
    "    print(f\"Checkpoint loaded, resuming training from epoch {start_epoch}\")\n",
    "else:\n",
    "    # If no checkpoint exists, initialize the model from scratch\n",
    "    score_model = torch.nn.DataParallel(UNet_Tranformer_attrb1(marginal_prob_std=marginal_prob_std_fn))\n",
    "    score_model = score_model.to(device)\n",
    "    optimizer = Adam(score_model.parameters(), lr=lr)\n",
    "    print(\"No checkpoint found, starting training from scratch\")\n",
    "    start_epoch = 0  # Start training from the first epoch\n",
    "\n",
    "scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[200,400,600,800,1000], gamma=0.5)#reduce the learing rate in every 200 epochs with the factor of gamma\n",
    "\n",
    "# add count parameter function below\n",
    "def count_parameters(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f'Total trainable parameters: {total_params}')\n",
    "count_parameters(score_model)\n",
    "\n",
    "\n",
    "tqdm_epoch = trange(n_epochs)\n",
    "\n",
    "# Create DataLoaders for both training and validation sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# Initialize tqdm loop\n",
    "tqdm_epoch = trange(n_epochs)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# should_stop = False\n",
    "for epoch in tqdm_epoch:\n",
    "    # print('epoch: ', epoch)\n",
    "    # Variables to track training progress\n",
    "    train_loss = 0.0\n",
    "    num_train_samples = 0\n",
    "\n",
    "    # if should_stop: #change 52a: add should_stop and add loss is nan check\n",
    "    #     break\n",
    "    scheduler.step()#change 57\n",
    "    score_model.train()  # Set model to training mode\n",
    "    # for gts, masks in train_loader:\n",
    "    for batch_idx, (gts, masks) in enumerate(train_loader):\n",
    "        x = gts.to(device)\n",
    "        y = masks.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(score_model, x, y, marginal_prob_std_fn)\n",
    "        if torch.isnan(loss): #if mini-loss on a batch is NaN, we skip that mini-loss from the total loss. In that case you can print information below to understand better\n",
    "            # print(f\"*********NaN loss detected at batch {batch_idx}, skipping batch.\")\n",
    "            # time_steps = x.shape[2]  # This should be 24 as per your input shape\n",
    "            # for t in range(time_steps):\n",
    "            #     x_t = x[0,0,t,:,:]\n",
    "            #     valid_x = x_t[~torch.isnan(x_t)]\n",
    "            #     if len(valid_x) > 0:  # Ensure there are non-NaN values\n",
    "            #         min_x = valid_x.min().item()\n",
    "            #         max_x = valid_x.max().item()\n",
    "            #     else:\n",
    "            #         min_x = 'No valid data'\n",
    "            #         max_x = 'No valid data'\n",
    "            #     print(\"time: \", t, f\" - Min: {min_x}, Max: {max_x}\", f\" - NaN count in x: {torch.isnan(x_t).sum().item()}\")\n",
    "            continue #change 59a: avoid NaN loss\n",
    "        # Clip gradients before optimizer step\n",
    "        torch.nn.utils.clip_grad_norm_(score_model.parameters(), max_norm=1.0)#change 59b: avoid NaN loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * x.shape[0]\n",
    "        num_train_samples += x.shape[0]\n",
    "\n",
    "    # Calculate average training loss\n",
    "    avg_train_loss = train_loss / num_train_samples\n",
    "\n",
    "    # Variables to track validation progress\n",
    "    val_loss = 0.0\n",
    "    num_val_samples = 0\n",
    "\n",
    "    score_model.eval()  # Set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for gts, masks in val_loader:\n",
    "            x = gts.to(device)\n",
    "            \n",
    "            y = masks.to(device)\n",
    "            loss = loss_fn(score_model, x, y, marginal_prob_std_fn)\n",
    "            val_loss += loss.item() * x.shape[0]\n",
    "            num_val_samples += x.shape[0]\n",
    "\n",
    "    # Calculate average validation loss\n",
    "    avg_val_loss = val_loss / num_val_samples\n",
    "\n",
    "    # Update the description for tqdm and print both training and validation losses\n",
    "    if epoch % 5 == 0:\n",
    "        tqdm_epoch.set_description(f'Epoch: {epoch} Train Loss: {avg_train_loss:.5f} Val Loss: {avg_val_loss:.5f}')#change 45a: epoch+pretrained-epoch here\n",
    "        print(f'Epoch: {epoch} Train Loss: {avg_train_loss:.5f} Val Loss: {avg_val_loss:.5f}')#change 45b: epoch+pretrained-epoch here\n",
    "    if epoch % 20 == 0: # print the learning rate#change 57\n",
    "        print(f\"Current LR: {optimizer.param_groups[0]['lr']}\")\n",
    "\n",
    "    train_losses.append(avg_train_loss)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    # Save the model checkpoint periodically\n",
    "    if (epoch % 100 == 0 and epoch >0) or (epoch == n_epochs - 1):  # Save every 100 epochs and at the last epoch\n",
    "        torch.save(score_model.state_dict(), f'ckpt_ConditionalMask_CMEMSdata_3D_Conv3D_widerUnet_batchsize{batch_size}_time{time_window}_Ep{epoch}.pth')#change 45c: epoch+pretrained-epoch here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot from the middle epoch, to zoom in the plot at the end of training phase\n",
    "start_ep = min(300, int(n_epochs/2))\n",
    "\n",
    "try:\n",
    "    epochs_display = range(start_ep, epoch)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(epochs_display,train_losses[start_ep:], label='Training Loss')\n",
    "    plt.plot(epochs_display,val_losses[start_ep:], label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "except:\n",
    "    epochs_display = range(start_ep, n_epochs)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(epochs_display,train_losses[start_ep:], label='Training Loss')\n",
    "    plt.plot(epochs_display,val_losses[start_ep:], label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0PdMMadpUbrj"
   },
   "source": [
    "## Sampling with Numerical SDE Solvers\n",
    "Recall that for any SDE of the form\n",
    "\\begin{align*}\n",
    "d \\mathbf{x} = \\mathbf{f}(\\mathbf{x}, t) dt + g(t) d\\mathbf{w},\n",
    "\\end{align*}\n",
    "the reverse-time SDE is given by\n",
    "\\begin{align*}\n",
    "d \\mathbf{x} = [\\mathbf{f}(\\mathbf{x}, t) - g(t)^2 \\nabla_\\mathbf{x} \\log p_t(\\mathbf{x})] dt + g(t) d \\bar{\\mathbf{w}}.\n",
    "\\end{align*}\n",
    "Since we have chosen the forward SDE to be\n",
    "\\begin{align*}\n",
    "d \\mathbf{x} = \\sigma^t d\\mathbf{w}, \\quad t\\in[0,1]\n",
    "\\end{align*}\n",
    "The reverse-time SDE is given by\n",
    "\\begin{align*}\n",
    "d\\mathbf{x} = -\\sigma^{2t} \\nabla_\\mathbf{x} \\log p_t(\\mathbf{x}) dt + \\sigma^t d \\bar{\\mathbf{w}}.\n",
    "\\end{align*}\n",
    "To sample from our time-dependent score-based model $s_\\theta(\\mathbf{x}, t)$, we first draw a sample from the prior distribution $p_1 \\approx \\mathbf{N}\\bigg(\\mathbf{x}; \\mathbf{0}, \\frac{1}{2}(\\sigma^{2} - 1) \\mathbf{I}\\bigg)$, and then solve the reverse-time SDE with numerical methods.\n",
    "\n",
    "In particular, using our time-dependent score-based model, the reverse-time SDE can be approximated by\n",
    "\\begin{align*}\n",
    "d\\mathbf{x} = -\\sigma^{2t} s_\\theta(\\mathbf{x}, t) dt + \\sigma^t d \\bar{\\mathbf{w}}\n",
    "\\end{align*}\n",
    "\n",
    "Next, one can use numerical methods to solve for the reverse-time SDE, such as the [Euler-Maruyama](https://en.wikipedia.org/wiki/Euler%E2%80%93Maruyama_method) approach. It is based on a simple discretization to the SDE, replacing $dt$ with $\\Delta t$ and $d \\mathbf{w}$ with $\\mathbf{z} \\sim \\mathcal{N}(\\mathbf{0}, g^2(t) \\Delta t \\mathbf{I})$. When applied to our reverse-time SDE, we can obtain the following iteration rule\n",
    "\\begin{align}\n",
    "\\mathbf{x}_{t-\\Delta t} = \\mathbf{x}_t + \\sigma^{2t} s_\\theta(\\mathbf{x}_t, t)\\Delta t + \\sigma^t\\sqrt{\\Delta t} \\mathbf{z}_t,\n",
    "\\end{align}\n",
    "where $\\mathbf{z}_t \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note that you can find other sampler methods in the original code of Song (ODE sampler, predictor-corrector and Euler-Maruyama sampler). For my dataset, I try all three samplers (ODE, predictor-corrector and Euler-Maruyama sampler) and I choose Euler-Maruyama sampler since it seems to be the best one on my case study.\n",
    "\n",
    "### Define the Euler-Maruyama sampler as below, here the sampler is extended one dimension to adapt the 3D setting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Define the Euler-Maruyama sampler (double click to expand or collapse)\n",
    "from tqdm.notebook import tqdm\n",
    "## The number of sampling steps.\n",
    "num_steps =  500#@param {'type':'integer'}\n",
    "def Euler_Maruyama_sampler(score_model, \n",
    "                           marginal_prob_std,\n",
    "                           diffusion_coeff, \n",
    "                           batch_size=64, \n",
    "                           num_steps=num_steps, \n",
    "                           device='cuda', \n",
    "                           time_window=None,\n",
    "                           y=None,#change 34b: add y here\n",
    "                           eps=1e-3):\n",
    "  \"\"\"Generate samples from score-based models with the Euler-Maruyama solver.\n",
    "\n",
    "  Args:\n",
    "    score_model: A PyTorch model that represents the time-dependent score-based model.\n",
    "    marginal_prob_std: A function that gives the standard deviation of\n",
    "      the perturbation kernel.\n",
    "    diffusion_coeff: A function that gives the diffusion coefficient of the SDE.\n",
    "    batch_size: The number of samplers to generate by calling this function once.\n",
    "    num_steps: The number of sampling steps. \n",
    "      Equivalent to the number of discretized time steps.\n",
    "    device: 'cuda' for running on GPUs, and 'cpu' for running on CPUs.\n",
    "    eps: The smallest time step for numerical stability.\n",
    "  \n",
    "  Returns:\n",
    "    Samples.    \n",
    "  \"\"\"\n",
    "  t = torch.ones(batch_size, device=device)\n",
    "  \n",
    "  #change 50: add more dimension below\n",
    "  init_x = torch.randn(batch_size, 1, time_window, size_0, size_1, device=device) \\\n",
    "    * marginal_prob_std(t)[:, None,  None,None,None] #change 49: time_window, size_0, size_1#change 50: add more dimension\n",
    "  time_steps = torch.linspace(1., eps, num_steps, device=device)\n",
    "  step_size = time_steps[0] - time_steps[1]\n",
    "  x = init_x\n",
    "\n",
    "  \n",
    "  with torch.no_grad():\n",
    "    for time_step in tqdm(time_steps):      \n",
    "      batch_time_step = torch.ones(batch_size, device=device) * time_step\n",
    "      # print(\"score_model(x, batch_time_step,y=y) shape: \",score_model(x, batch_time_step,y=y).shape)\n",
    "      g = diffusion_coeff(batch_time_step)\n",
    "      mean_x = x + (g**2)[:, None, None, None,None] * score_model(x, batch_time_step,y=y) * step_size #change 34b: add y here#change 50: add more dimension\n",
    "      x = mean_x + torch.sqrt(step_size) * g[:,None,  None,  None,None] * torch.randn_like(x)  #change 50: add more dimension    \n",
    "  # Do not include any noise in the last sampling step.\n",
    "  return mean_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Dataset Configuration\n",
    "\n",
    "For evaluation purposes, I have created an additional XArrayDataset as detailed below. This dataset is used to evaluate performance across the entire validation set without restrictions on the percentage of NaN areas. This approach differs from the initial DataLoader setup (at the beginning of this Jupyter notebook), where inputs with insufficient data were excluded to avoid NaN values when computing the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate on the whole 1 year dataset, but only inside the considered subset area\n",
    "\n",
    "class XArrayDatasetWithMask_wholedataset(Dataset):\n",
    "    def __init__(self, GT, GT_mask, crop_size, output_size, time_window=None, transform=None):\n",
    "        self.GT_data = GT['SPM'].values  # Assuming 'SPM' is the variable in the dataset\n",
    "        self.mask_data = GT_mask['SPM'].values  \n",
    "        self.crop_size = crop_size\n",
    "        self.output_size = output_size\n",
    "        self.transform = transform\n",
    "        self.time_window = time_window \n",
    "        self.random_crop = transforms.RandomCrop(crop_size)  # Random crop transformation\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.GT_data.shape[0] - self.time_window + 1  \n",
    "    \n",
    "    def __getitem__(self, idx): \n",
    "        gt_sample = self.GT_data[idx:idx+self.time_window]  # Select a time window\n",
    "        mask_sample = self.mask_data[idx:idx+self.time_window]\n",
    "        \n",
    "        gt_sample = torch.tensor(gt_sample, dtype=torch.float32).unsqueeze(1)#the size will be (time_window, 1, size_0, size_1 here)\n",
    "        mask_sample = torch.tensor(mask_sample, dtype=torch.float32).unsqueeze(1)\n",
    " \n",
    "        i, j, h, w = 0,60,size_0,size_1\n",
    "        # print(\"gt_sample.shape before crop: \", gt_sample.shape)\n",
    "        gt_sample=transforms.functional.crop(gt_sample, i, j, h, w).squeeze(1).unsqueeze(0) #so that the dimension will be (time_window,1, size_0,size_1)\n",
    "        mask_sample=transforms.functional.crop(mask_sample, i, j, h, w).squeeze(1).unsqueeze(0)\n",
    "  \n",
    "        return gt_sample, mask_sample\n",
    "    \n",
    "\n",
    "dataset = XArrayDatasetWithMask_wholedataset(GT_val, GT_with_artificialgappy_val, crop_size=crop_size, output_size=output_size, time_window=time_window)#use val dataset here since we will use it below for evaluation purpose\n",
    "print(\"GT_val\", GT_val)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling Process and Evaluation framework\n",
    "\n",
    "In both training and sampling, the input is 3D, encompassing a time window along with width and height dimensions. Specifically, our input is of size 16x112x112, where '16' represents 16 consecutive days (days 0 through 15). For evaluation purposes, we focus on extracting and plotting data from the middle of the time window, which corresponds to day 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Sampling for the whole dataset (except the first and last images)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "device = 'cuda' #@param ['cuda', 'cpu'] {'type':'string'}\n",
    "\n",
    "#(optional) if you have other weight, you can load it the 2 lines below:\n",
    "# ckpt = torch.load('/homes/n23nguye/Score-Based-Generative-Modeling-Tutorial/scorebased-diffusion/code/ckpt_ConditionalMask_CMEMSdata_3D_Conv3D_widerUnet_smallerbatchsize8_time16_Ep1000.pth', map_location=device)\n",
    "# score_model.load_state_dict(ckpt)\n",
    "\n",
    "sampler = Euler_Maruyama_sampler #You can find different sampler in the original code of Song which contains 3 samplers: 'Euler_Maruyama_sampler', 'pc_sampler', 'ode_sampler'. I chose Euler_Maruyama_sampler since it seems to be the best for my data.\n",
    "sample_batch_size = 100 # Set the batch size for sampling\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=sample_batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# Prepare to collect samples, averages/ensembles of all samples, and original data for comparison\n",
    "all_samples = []\n",
    "all_samples_avg = []\n",
    "all_originals = []\n",
    "all_masks = []\n",
    "\n",
    "# Define the window to plot (middle window)\n",
    "plot_window=int(time_window/2)-1 #here, we choose the middle one to plot. For example, our input is of size 16*112*112 where 16 indicate 16 consecutive days (day 0, 1, 2, ...15), we extract the middle day which is day 7\n",
    "\n",
    "\n",
    "for idx, (original_images, mask_images) in enumerate(data_loader):\n",
    "    print(f\"Processing batch index: {idx}\")\n",
    "    mask_images = mask_images.to(device)  # Ensure masks are on the correct device\n",
    "    mask_images_NantoZero = torch.nan_to_num(mask_images, nan=0.0) # replace Nan by Zero to avoid NaN in computation\n",
    "\n",
    "    # Perform multiple sampling experiments below. A larger number of samples will provide a better ensemble, but takes longer time for process\n",
    "    N_experiments=10\n",
    "\n",
    "    for n_ep in range(N_experiments):\n",
    "        print(\"n_ep\", n_ep)\n",
    "        samples = sampler(score_model,\n",
    "                        marginal_prob_std_fn,\n",
    "                        diffusion_coeff_fn,\n",
    "                        mask_images.shape[0],#note that, the last batch might have different shape compared to sample_batch_size\n",
    "                        y=mask_images_NantoZero,\n",
    "                        time_window=time_window,\n",
    "                        device=device)\n",
    "        if n_ep==0:\n",
    "            samples_avg=samples.clone()\n",
    "        else:\n",
    "            samples_avg+=samples\n",
    "\n",
    "\n",
    "    samples_avg=samples_avg/N_experiments\n",
    "\n",
    "    # Convert tensors to NumPy for analysis and plotting\n",
    "    samples_avg_np = samples_avg.cpu().numpy()  \n",
    "    samples_np = samples.cpu().numpy()\n",
    "    mask_images_np = mask_images.cpu().numpy() \n",
    "    original_images_np = original_images.cpu().numpy() \n",
    "    \n",
    "    \n",
    "    # Store the specified window for each sample and mask\n",
    "    all_samples.append(samples_np[:,0,plot_window,:,:])\n",
    "    all_samples_avg.append(samples_avg_np[:,0,plot_window,:,:])\n",
    "    all_masks.append(mask_images_np[:,0,plot_window,:,:])\n",
    "    all_originals.append(original_images_np[:,0,plot_window,:,:])\n",
    "\n",
    "\n",
    "# After processing all batches, convert lists to NumPy arrays and Concatenate lists to form complete arrays\n",
    "all_samples = np.concatenate(all_samples, axis=0)\n",
    "all_samples_avg = np.concatenate(all_samples_avg, axis=0)\n",
    "all_masks = np.concatenate(all_masks, axis=0)\n",
    "all_originals = np.concatenate(all_originals, axis=0)\n",
    "\n",
    "\n",
    "# Define metrics for evaluation\n",
    "def rmse(x, y):\n",
    "    \"\"\" Compute Root Mean Squared Error \"\"\"\n",
    "    return np.sqrt(np.mean((x - y) ** 2))\n",
    "\n",
    "def RE(gt, pred):\n",
    "    \"\"\" Compute Relative Error \"\"\"\n",
    "    ep = 0.0001  # Small epsilon to avoid division by zero\n",
    "    return np.mean(np.abs((10 ** gt + ep) - (10 ** pred + ep)) / np.abs(10 ** gt + ep)) * 100\n",
    "\n",
    "# Apply metrics to valid (non-NaN) data points\n",
    "valid_mask = ~np.isnan(all_originals) & np.isnan(all_masks)\n",
    "\n",
    "gt_flat = all_originals[valid_mask]\n",
    "samples_flat = all_samples[valid_mask]\n",
    "samples_avg_flat = all_samples_avg[valid_mask]\n",
    "\n",
    "# Print output results\n",
    "print('Evaluation for Diffusion: ')\n",
    "print(f\"RMSE 1 sample: {rmse(gt_flat, samples_flat):.3f}\")\n",
    "print(f\"RE 1 sample: {RE(gt_flat, samples_flat):.3f}%\")\n",
    "\n",
    "print(f\"RMSE {N_experiments} samples: {rmse(gt_flat, samples_avg_flat):.3f}\")\n",
    "print(f\"RE {N_experiments} samples: {RE(gt_flat, samples_avg_flat):.3f}%\")\n",
    "\n",
    "print(\" np.unique(original_images_np) : \", np.unique(original_images_np))\n",
    "print(\" np.unique(mask_images_np) : \", np.unique(mask_images_np))\n",
    "print(\"np.unique(samples_np): \", np.unique(samples_np))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please change the path of land_mask before running this below visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the land mask, please change the path below:\n",
    "land_mask=xr.open_dataarray('/Odyssey/private/n23nguye/data_nga/Delft3Dmodel_CMEMS_size200T300/CMEMS/land_mask_CMEMS_size200T300.nc')\n",
    "\n",
    "# Parameters for the cropped area used in evaluation, here we choose an area near the coast with high turbidity\n",
    "i, j, h, w = 0, 60,size_0,size_1 #the parameters for the cropped area used in evaluation, we want to choose an area near the coastal with high turbidity \n",
    "land_mask=land_mask.values[i:i + h, j:j + w]\n",
    "\n",
    "# Set color scale limits for better contrast visually display in the plot\n",
    "v_min=-1\n",
    "v_max=2\n",
    "\n",
    "#x, y are latitude and longitude\n",
    "x = np.arange(0, h ) \n",
    "y = np.arange(0, w)\n",
    "\n",
    "# Loop through selected time frames, select the range time you want to display\n",
    "for t in range(100,120,1):\n",
    "\n",
    "    fig, axes = plt.subplots(1, 4, figsize=[6*4+2*4, 6])  # Adjust the figsize if needed\n",
    "\n",
    "    # Plot the first image\n",
    "    # print(\"x.shape, y.shape, mask_images_np[t,0, plot_window].shape: \",x.shape, y.shape, mask_images_np[t,0, plot_window].shape)\n",
    "    mappable0 = axes[0].pcolormesh(x, y, all_masks[t], cmap='jet', vmin=v_min, vmax=v_max)\n",
    "    axes[0].pcolormesh(x, y, land_mask, cmap='gray', vmin=0, vmax=2)\n",
    "    axes[0].set_title(\"Mask\")\n",
    "    fig.colorbar(mappable0, ax=axes[0])\n",
    "\n",
    "    # Plot the second image (simulated observation)\n",
    "    mappable1 = axes[1].pcolormesh(x, y, all_samples[t], cmap='jet', vmin=v_min, vmax=v_max)\n",
    "    axes[1].pcolormesh(x, y, land_mask, cmap='gray', vmin=0, vmax=2)\n",
    "    axes[1].set_title(\"1 Sample\")\n",
    "    fig.colorbar(mappable1, ax=axes[1])\n",
    "\n",
    "   \n",
    "    # Plot the third image (another simulated observation)\n",
    "    mappable2 = axes[2].pcolormesh(x, y, all_samples_avg[t], cmap='jet', vmin=v_min, vmax=v_max)\n",
    "    axes[2].pcolormesh(x, y, land_mask, cmap='gray', vmin=0, vmax=2)\n",
    "    axes[2].set_title(f'Ensemble of {N_experiments} samples')\n",
    "    fig.colorbar(mappable2, ax=axes[2])\n",
    "\n",
    "    # Plot the third image (another simulated observation)\n",
    "    mappable3 = axes[3].pcolormesh(x, y, all_originals[t], cmap='jet', vmin=v_min, vmax=v_max)\n",
    "    axes[3].pcolormesh(x, y, land_mask, cmap='gray', vmin=0, vmax=2)\n",
    "    axes[3].set_title(\"Ground truth\")\n",
    "    fig.colorbar(mappable3, ax=axes[3])\n",
    "\n",
    "\n",
    "    # filename = f'plots/ckpt_Nan_ConditionalMask_lsubsetnotfixed_losswholeimage_CMEMSdata_TrainValSeparate_3D_Ep999_{N_experiments}_sample_{t}.png'\n",
    "    # plt.savefig(filename)  # Save the figure to a file\n",
    "\n",
    "    plt.show()  # Display the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "By increasing number of training epochs (n_epochs to 1000), increasing number of steps in sampling method (num_steps to 1000 or 2000 for example), and increasing the number of samples (N_experiments to 10 or more for examples), and increase the channels of UNet to [64, 128, 256, 512], we'll get a bit better interpolation, however it will increase the computing time a lot."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "1CzbeDmhkJ05ro5l1H3rGSgN7L3xbo6fg",
     "timestamp": 1723555169369
    },
    {
     "file_id": "120kYYBOVa1i0TD85RjlEkFjaWDxSFUx3",
     "timestamp": 1723106048284
    },
    {
     "file_id": "1YbT61SuuIc2mcYWH7KA_Gv49EN3M8VE4",
     "timestamp": 1611090576605
    },
    {
     "file_id": "1gJGl7J18aP9jR5_2gjwQOcn8RWZegUR6",
     "timestamp": 1603207633254
    }
   ]
  },
  "kernelspec": {
   "display_name": "diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
